# backend.py

import os
import re
import subprocess
import pathlib
import requests
from dotenv import load_dotenv
from Embedding import watsonx_embedding, vectorstore

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
WATSONX_API = os.environ['API_KEY']
PROJECT_ID = os.environ['PROJECT_ID']
IBM_URL = os.environ['IBM_CLOUD_URL']
WATSONX_ENDPOINT = 'https://us-south.ml.cloud.ibm.com/ml/v1/deployments/47f04daa-ce50-4317-8712-bef7dc271031/text/generation?version=2021-05-01'


# 2. ì‚¬ì „ ì •ì˜ëœ ìŠ¤ë¯¸ì‹± ë©”ì‹œì§€/URL ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
with open("./smishing_URL.csv", "r", encoding="utf-8") as f:
    known_urls = set(line.strip() for line in f if line.strip())
with open("./labeled_smishing_messages.csv", "r", encoding="utf-8") as f:
    known_messages = set(line.strip() for line in f if line.strip())


# 3. ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ì—ì„œ URL ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (1ë‹¨ê³„ì—ì„œ ë‹¨ìˆœ ë¹„êµ)
def extract_urls(text: str):
    url_pattern = r"""(?i)\b(https?://|www\\.)?[a-z0-9.-]+\\.[a-z]{2,}(/[\\w./?%&=:#@!~+-]*)?"""
    return re.findall(url_pattern, text)


# 4. Vector DB ì¡´ì¬ ì—¬ë¶€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
VECTOR_DB_DIR = "./chroma_store"
def ensure_vector_db():
    db_ready = pathlib.Path(VECTOR_DB_DIR).exists() and len(os.listdir(VECTOR_DB_DIR)) > 0
    if not db_ready:
        print("â—ï¸ë²¡í„° DBê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ Embedding.pyë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        subprocess.run(["python", "Embedding.py"], check=True)
    else:
        print("âœ… ê¸°ì¡´ ë²¡í„° DBê°€ í™•ì¸ë˜ì–´ ë°”ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.")


# 5. Watsonx Prompt Lab Endpoint í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜
def call_watsonx_endpoint(user_input: str, similar_cases: str) -> str:
    # (1) IBM Cloud IAM ì¸ì¦ í† í° ë°œê¸‰
    token_response = requests.post(
        "https://iam.cloud.ibm.com/identity/token",
        data={
            "apikey": WATSONX_API,
            "grant_type": "urn:ibm:params:oauth:grant-type:apikey"
        }
    )
    mltoken = token_response.json().get("access_token")
    if not mltoken:
        raise Exception("âŒ IBM Cloud í† í° ë°œê¸‰ ì‹¤íŒ¨")

    # (2) ìš”ì²­ í—¤ë”
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {mltoken}",
        "Accept": "text/event-stream"
    }

    # (3) Watsonx Prompt Lab í˜¸ì¶œìš© í˜ì´ë¡œë“œ
    payload = {
        "parameters": {
            "prompt_variables": {
                "user_input": user_input,
                "similar_cases": similar_cases
            }
        }
    }

    # (4) Watsonx API ìš”ì²­
    response = requests.post(
        WATSONX_ENDPOINT,
        headers=headers,
        json=payload,
        stream=False
    )

    # (5) ì‘ë‹µ ì²´í¬
    try:
        response_json = response.json()
        return response_json["results"][0]["generated_text"].strip()
    except Exception as e:
        raise Exception(f"âŒ Watsonx ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\nğŸ“­ ì‘ë‹µ ì›ë¬¸: {response.text}")


# 6. ì‘ë‹µ íŒŒì‹± í•¨ìˆ˜
def parse_ai_response(response_text: str) -> dict:
    try:
        # 1. label ì¶”ì¶œ: '1. ìµœì¢… íŒë‹¨:' ~ '2. íŒë‹¨ ê·¼ê±°' ì´ì „ê¹Œì§€
        label_match = re.search(r"1\.\s*ìµœì¢… íŒë‹¨[:ï¼š]?\s*(.*?)\n\s*2\.", response_text, re.DOTALL)
        label = label_match.group(1).strip() if label_match else "ë¶„ì„ ì‹¤íŒ¨"

        # 2. reason ì¶”ì¶œ: '2. íŒë‹¨ ê·¼ê±°:' ~ '3. ìœ„í—˜ë„' ì´ì „ê¹Œì§€
        reason_match = re.search(r"2\.\s*íŒë‹¨ ê·¼ê±°[:ï¼š]?\s*((?:.|\n)*?)\n\s*3\.", response_text)
        reason = reason_match.group(1).strip() if reason_match else "íŒë‹¨ ê·¼ê±°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 3. confidence ì¶”ì¶œ: '3. ìœ„í—˜ë„:' ~ '%'ê¹Œì§€ í¬í•¨
        confidence_match = re.search(r"3\.\s*ìœ„í—˜ë„[:ï¼š]?\s*([^\n%]+%)", response_text)
        confidence = confidence_match.group(1).strip() if confidence_match else "0%"

        return {
            "label": label,
            "confidence": confidence,
            "reason": reason
        }
    except Exception as e:
        return {
            "label": "íŒë‹¨ ì‹¤íŒ¨",
            "confidence": "0%",
            "reason": f"âŒ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}"
        }

# 7. ìµœì¢… íŒë‹¨ í•¨ìˆ˜
def classify_message(user_input: str) -> dict:
    cleaned_input = user_input.strip()

    # (1) 1ì°¨ ì‚¬ì „ í•„í„°ë§
    urls_in_message = extract_urls(cleaned_input)
    if cleaned_input in known_messages:
        return {
            "label": "ìŠ¤ë¯¸ì‹±",
            "confidence": 1.0,
            "reason": "ì‚¬ì „ ë“±ë¡ëœ ìŠ¤ë¯¸ì‹± ë©”ì‹œì§€ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤."
        }
    if any(url in known_urls for url in urls_in_message):
        return {
            "label": "ìŠ¤ë¯¸ì‹±",
            "confidence": 1.0,
            "reason": "ì‚¬ì „ ë“±ë¡ëœ ìŠ¤ë¯¸ì‹± URLì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        }


    # (2) ì„ë² ë”© / Vector DB ê²€ìƒ‰
    ensure_vector_db() # VectorDBê°€ ì´ë¯¸ êµ¬ì¶•ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    try:
        # 1. ì…ë ¥ ë©”ì‹œì§€ë¥¼ ì„ë² ë”©
        query_embedding = watsonx_embedding.embed_query(cleaned_input)

        # 2. ìœ ì‚¬ ë©”ì‹œì§€ ê²€ìƒ‰ (ì˜ˆ: ìƒìœ„ 3ê°œ)
        docs = vectorstore.similarity_search_by_vector(query_embedding, k=3)

        # 3. ìœ ì‚¬ ë©”ì‹œì§€ë¥¼ ë¬¸ìì—´ë¡œ ì •ë¦¬
        retrieved_texts = "\n".join([f"- {doc.page_content}" for doc in docs])

    except Exception as e:
        return {
            "label": "íŒë‹¨ ì‹¤íŒ¨",
            "confidence": 0.0,
            "reason": f"Vector DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        }


    # (3) 2ì°¨ AI íŒë‹¨ (ì™“ìŠ¨ í˜¸ì¶œ)
    try:
        ai_response = call_watsonx_endpoint(user_input=cleaned_input, similar_cases=retrieved_texts)
        print("ğŸ“­ Watsonx ì‘ë‹µ í…ìŠ¤íŠ¸:")
        parsed_result = parse_ai_response(ai_response)

        return parsed_result
    
    except Exception as e:
        return {
            "label": "íŒë‹¨ ì‹¤íŒ¨",
            "confidence": 0.0,
            "reason": f"AI ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        }


# 8. ë³´í˜¸ìì—ê²Œ ì•Œë¦¼ ë³´ë‚´ëŠ” í•¨ìˆ˜

# 9. ëŒ€ì‘ ê°€ì´ë“œ ì•ˆë‚´í•˜ëŠ” í•¨ìˆ˜